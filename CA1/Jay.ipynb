{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "def create_cnn_model(num_conv_layers, num_dense_layers, num_filters=64, kernel_size=(3, 3)):\n",
    "    # Initialize a Sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Add convolutional layers\n",
    "    for i in range(num_conv_layers):\n",
    "        if i == 0:\n",
    "            model.add(Conv2D(num_filters, kernel_size, input_shape=(131, 131, 1), activation='relu'))\n",
    "        else:\n",
    "            model.add(Conv2D(num_filters, kernel_size, activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # Add dropout layer\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    # Flatten the output of the last convolutional layer\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # Add dense layers\n",
    "    for _ in range(num_dense_layers):\n",
    "        model.add(Dense(256, activation='relu'))\n",
    "    \n",
    "    # Output layer\n",
    "    model.add(Dense(15, activation='softmax'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Define the number of convolutional and dense layers to experiment with\n",
    "num_conv_layers_list = [3, 4, 5]\n",
    "num_dense_layers_list = [1, 2, 3, 4]\n",
    "\n",
    "best_accuracy = 0.0\n",
    "best_loss = float('inf')\n",
    "best_model_configuration = None\n",
    "\n",
    "# Train and evaluate models with different configurations\n",
    "for num_conv_layers in num_conv_layers_list:\n",
    "    for num_dense_layers in num_dense_layers_list:\n",
    "        print(f\"Number of Conv Layers: {num_conv_layers}, Number of Dense Layers: {num_dense_layers}\")\n",
    "        \n",
    "        # Create the model with default values for num_filters and kernel_size\n",
    "        model = create_cnn_model(num_conv_layers, num_dense_layers)\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(X_train_preprocessed, y_train, validation_data=(X_val_preprocessed, y_val), epochs = 100, batch_size = 64, callbacks = [Early_Stopping], verbose=0)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        loss, accuracy = model.evaluate(X_test_preprocessed, y_test, verbose=0)\n",
    "        print(\"Test Loss: %.4f, Test Accuracy: %.2f%%\" % (loss, accuracy * 100)) # Print test accuracy\n",
    "\n",
    "        # Update best model configuration based on accuracy and lossfe \n",
    "        if accuracy > best_accuracy and loss < best_loss:\n",
    "            best_accuracy = accuracy\n",
    "            best_loss = loss\n",
    "            best_model_configuration = (num_conv_layers, num_dense_layers)\n",
    "\n",
    "print(\"\\nBest Model Configuration - Number of Conv Layers: %d, Number of Dense Layers: %d, Test Loss: %.4f, Test Accuracy: %.2f%%\" % (best_model_configuration[0], best_model_configuration[1], best_loss, best_accuracy * 100))import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "def create_cnn_model(num_conv_layers, num_dense_layers, num_filters=64, kernel_size=(3, 3)):\n",
    "    # Initialize a Sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Add convolutional layers\n",
    "    for i in range(num_conv_layers):\n",
    "        if i == 0:\n",
    "            model.add(Conv2D(num_filters, kernel_size, input_shape=(131, 131, 1), activation='relu'))\n",
    "        else:\n",
    "            model.add(Conv2D(num_filters, kernel_size, activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # Add dropout layer\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    # Flatten the output of the last convolutional layer\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # Add dense layers\n",
    "    for _ in range(num_dense_layers):\n",
    "        model.add(Dense(256, activation='relu'))\n",
    "    \n",
    "    # Output layer\n",
    "    model.add(Dense(15, activation='softmax'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Define the number of convolutional and dense layers to experiment with\n",
    "num_conv_layers_list = [3, 4, 5]\n",
    "num_dense_layers_list = [1, 2, 3, 4]\n",
    "\n",
    "best_accuracy = 0.0\n",
    "best_loss = float('inf')\n",
    "best_model_configuration = None\n",
    "\n",
    "# Train and evaluate models with different configurations\n",
    "for num_conv_layers in num_conv_layers_list:\n",
    "    for num_dense_layers in num_dense_layers_list:\n",
    "        print(f\"Number of Conv Layers: {num_conv_layers}, Number of Dense Layers: {num_dense_layers}\")\n",
    "        \n",
    "        # Create the model with default values for num_filters and kernel_size\n",
    "        model = create_cnn_model(num_conv_layers, num_dense_layers)\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(X_train_preprocessed, y_train, validation_data=(X_val_preprocessed, y_val), epochs = 100, batch_size = 64, callbacks = [Early_Stopping], verbose=0)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        loss, accuracy = model.evaluate(X_test_preprocessed, y_test, verbose=0)\n",
    "        print(\"Test Loss: %.4f, Test Accuracy: %.2f%%\" % (loss, accuracy * 100)) # Print test accuracy\n",
    "\n",
    "        # Update best model configuration based on accuracy and lossfe \n",
    "        if accuracy > best_accuracy and loss < best_loss:\n",
    "            best_accuracy = accuracy\n",
    "            best_loss = loss\n",
    "            best_model_configuration = (num_conv_layers, num_dense_layers)\n",
    "\n",
    "print(\"\\nBest Model Configuration - Number of Conv Layers: %d, Number of Dense Layers: %d, Test Loss: %.4f, Test Accuracy: %.2f%%\" % (best_model_configuration[0], best_model_configuration[1], best_loss, best_accuracy * 100))import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "def create_cnn_model(num_conv_layers, num_dense_layers, num_filters=64, kernel_size=(3, 3)):\n",
    "    # Initialize a Sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Add convolutional layers\n",
    "    for i in range(num_conv_layers):\n",
    "        if i == 0:\n",
    "            model.add(Conv2D(num_filters, kernel_size, input_shape=(131, 131, 1), activation='relu'))\n",
    "        else:\n",
    "            model.add(Conv2D(num_filters, kernel_size, activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # Add dropout layer\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    # Flatten the output of the last convolutional layer\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # Add dense layers\n",
    "    for _ in range(num_dense_layers):\n",
    "        model.add(Dense(256, activation='relu'))\n",
    "    \n",
    "    # Output layer\n",
    "    model.add(Dense(15, activation='softmax'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Define the number of convolutional and dense layers to experiment with\n",
    "num_conv_layers_list = [3, 4, 5]\n",
    "num_dense_layers_list = [1, 2, 3, 4]\n",
    "\n",
    "best_accuracy = 0.0\n",
    "best_loss = float('inf')\n",
    "best_model_configuration = None\n",
    "\n",
    "# Train and evaluate models with different configurations\n",
    "for num_conv_layers in num_conv_layers_list:\n",
    "    for num_dense_layers in num_dense_layers_list:\n",
    "        print(f\"Number of Conv Layers: {num_conv_layers}, Number of Dense Layers: {num_dense_layers}\")\n",
    "        \n",
    "        # Create the model with default values for num_filters and kernel_size\n",
    "        model = create_cnn_model(num_conv_layers, num_dense_layers)\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(X_train_preprocessed, y_train, validation_data=(X_val_preprocessed, y_val), epochs = 100, batch_size = 64, callbacks = [Early_Stopping], verbose=0)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        loss, accuracy = model.evaluate(X_test_preprocessed, y_test, verbose=0)\n",
    "        print(\"Test Loss: %.4f, Test Accuracy: %.2f%%\" % (loss, accuracy * 100)) # Print test accuracy\n",
    "\n",
    "        # Update best model configuration based on accuracy and lossfe \n",
    "        if accuracy > best_accuracy and loss < best_loss:\n",
    "            best_accuracy = accuracy\n",
    "            best_loss = loss\n",
    "            best_model_configuration = (num_conv_layers, num_dense_layers)\n",
    "\n",
    "print(\"\\nBest Model Configuration - Number of Conv Layers: %d, Number of Dense Layers: %d, Test Loss: %.4f, Test Accuracy: %.2f%%\" % (best_model_configuration[0], best_model_configuration[1], best_loss, best_accuracy * 100))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
