{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(42, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow Hello World\n",
    "import tensorflow as tf\n",
    "#sess = tf.Session() # This is only needed for TF 1.X\n",
    "# Computational Graph to be compiled and then run using the session\n",
    "a = tf.constant(10)\n",
    "b = tf.constant(32)\n",
    "# print(sess.run(a+b)) # Not session.run not needed in TF2.X\n",
    "# In TF2.X eager execution compiles the computation graph in the background\n",
    "print(a+b) # TF 2.X is more direct. Just write a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras Hello World\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',\n",
    " metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: [-0.12725714], b: [0.62730837]\n",
      "W: [0.03091183], b: [0.3394586]\n",
      "W: [0.08471694], b: [0.3087287]\n",
      "W: [0.09661921], b: [0.3019309]\n",
      "W: [0.09925213], b: [0.30042714]\n",
      "W: [0.09983456], b: [0.30009452]\n",
      "W: [0.09996341], b: [0.3000209]\n",
      "W: [0.09999192], b: [0.30000463]\n",
      "W: [0.09999822], b: [0.30000103]\n",
      "W: [0.09999961], b: [0.30000025]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Create 100 phony x, y data points in NumPy, y = x * 0.1 + 0.3\n",
    "x_data = np.random.rand(100).astype(np.float32)\n",
    "y_data = x_data * 0.1 + 0.3\n",
    "\n",
    "# Try to find values for W and b that compute y_data = W * x_data + b\n",
    "# (We know that W should be 0.1 and b 0.3, but Tensorflow will\n",
    "# figure that out for us.)\n",
    "W = tf.Variable(tf.random.uniform(shape=(1,), minval=-1.0, maxval=1.0))\n",
    "b = tf.Variable(tf.zeros(shape=(1,)))\n",
    "\n",
    "# Minimize the mean squared errors.\n",
    "def cost():\n",
    "    y = W * x_data + b\n",
    "    loss = tf.reduce_mean(tf.square(y - y_data))\n",
    "    return loss\n",
    "\n",
    "# SGD is the equivalent for GradientDescentOptimizer\n",
    "optimizer = tf.optimizers.SGD(0.5)\n",
    "for e in range(200):\n",
    "    optimizer.minimize(cost, var_list=[W, b])\n",
    "    if e % 20 == 0:\n",
    "        print(f'W: {W.numpy()}, b: {b.numpy()}')    \n",
    "# Learns best fit is W: [0.1], b: [0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorflow_version` not found.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "# create model\n",
    "model = Sequential([\n",
    "Dense(12, input_dim=8, activation='relu'),\n",
    "Dense(8, activation='relu'),\n",
    "Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use input_shape\n",
    "model.add(Dense(32, input_shape=(784,)))\n",
    "# or input_dim\n",
    "model.add(Dense(32, input_dim=784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 4s 4ms/step - loss: 0.6936 - accuracy: 0.5375\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6810 - accuracy: 0.8250\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6686 - accuracy: 0.8875\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6537 - accuracy: 0.9625\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6350 - accuracy: 0.9750\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6117 - accuracy: 0.9875\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5857 - accuracy: 0.9875\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5555 - accuracy: 0.9875\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5203 - accuracy: 0.9875\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4829 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 0.4674 - accuracy: 1.0000\n",
      "\n",
      "accuracy: 100.00%\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "[0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "# Keras version of Iris classifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn import datasets\n",
    "from sklearn import model_selection\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# loading and pre-processing of the data\n",
    "# We use the 2 class version of iris data set\n",
    "iris = pd.read_csv(\"IrisTwoClass.csv\")\n",
    "x = np.array(iris.drop(\"Class\",axis=1))\n",
    "y = np.array(iris[\"Class\"])\n",
    "# Split dataset into train / test\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(\n",
    " x, y, test_size=0.2, random_state=42)\n",
    "# Scale data (training set) to 0 mean and unit standard deviation.\n",
    "scaler = preprocessing.StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.fit_transform(x_test)\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=4, activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',\n",
    " metrics=['accuracy'])\n",
    "# training the model\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=10)\n",
    "# eval model\n",
    "scores = model.evaluate(x_test, y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "# calculate predictions\n",
    "predictions = model.predict(x_test)\n",
    "# round predictions\n",
    "rounded = [round(x[0]) for x in predictions]\n",
    "print(rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 25ms/step - loss: 0.6294 - accuracy: 0.4875\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4993 - accuracy: 0.9875\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3797 - accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.2784 - accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.1974 - accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1369 - accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0954 - accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0654 - accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0463 - accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0338 - accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0255 - accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0198 - accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0159 - accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0130 - accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0108 - accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0092 - accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 32ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9.8159e-04 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9.3519e-04 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 8.9247e-04 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 8.5187e-04 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8.1467e-04 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 7.7987e-04 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 7.4677e-04 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7.1611e-04 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6.8741e-04 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 6.5981e-04 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 6.3484e-04 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6.1108e-04 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 5.8788e-04 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 5.6629e-04 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 5.4628e-04 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 5.2685e-04 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 5.0872e-04 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 4.9146e-04 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4.7518e-04 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 4.5943e-04 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 4.4440e-04 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 4.3036e-04 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 4.1738e-04 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 4.0402e-04 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.9194e-04 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3.8025e-04 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3.6886e-04 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.5827e-04 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.4793e-04 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.3813e-04 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.2868e-04 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.1970e-04 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.1092e-04 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.0274e-04 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.9486e-04 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.8706e-04 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.7966e-04 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.7269e-04 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.6573e-04 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.5913e-04 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.5285e-04 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.4687e-04 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.4079e-04 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.3507e-04 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.2965e-04 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.2433e-04 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.1915e-04 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.1431e-04 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.0948e-04 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 2.0479e-04 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.0032e-04 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.9606e-04 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.9184e-04 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.8787e-04 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.8384e-04 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.7989e-04 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.7647e-04 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.7262e-04 - accuracy: 1.0000\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n",
      "input_18 [(None, 4)]\n",
      "dense_67 (None, 64)\n",
      "dense_68 (None, 64)\n",
      "dense_69 (None, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMUAAAAbCAYAAADMDEuvAAAEP0lEQVR4Ae2cWUgUcRzHv6auWh6om5gYeVWmVBBEdFNZYhc91Ev00qMvPgU9hJKvIhUYkRQ9SD1EEKWYVoSxRh4dSmiJR6xmut5Huum4q82s7NbuzjozO4c79JuXnfmfv9/3O5+dg/1v0BK7wc/t/t2bKCy8hn07E/wcwb3bp6+j6Bucxf4DB5CUlOReqeLRSLcZ7W1t2BOdqMgsrdPD6GdmKA8/1VTDj5+sH5WVVTh15rRgVCGCLXw04IAovl6El3eOI2NjtI9W4osLShoxz9gRHxuO8vJyZGVlie8so+W90lsorqrB0x2nkRoRI2Ok5a5XO+sxv2RHXGgE5eGHmmr5Ecv6kZqeJiqiNaJaeTRyAlFddlQxIKpN/Xh+4xDiY8I9ZlPv0GFAUREeZ+cpBsSr8V482pKDOAPlIdW5QPFDMhRqApGWHClVR7/bq2lASrj8K6fYxCgPfqW4K7bzC0qqH5KgICCUN4B/RHGlBAS/TnKA4EYUDQUBoY4B/KMKlxIQ/BrJBYIbNUjM26eC/Et4UV2FtWHBMISK5og/arbUZl9CV98U9m43Yt1a92f9ug/D2HfwKKKjlb8F6f34BSMWCyKCQxAaJD8PO/virsc6id2R67EuONQt3/rpQezPoTzcRPE4UMOPqYU5PMg4As9bppMdL/Cs+Z2oFzjuZ6RH0NwhwzCYnprErkwjLpxI42khvejJq+8IZs/Ji3mbvDp//DqB3NxcJCcne9XJKbDZbKjo6cMG6yLOJW6WM5Sr7zNLl+NSe96Y7ipz7rRYxygPpxg8n2r58Xth3gsInulXLBKEwmAwICUlFYixKAZFe88ErHMMzh72PvFLKjodJ5Mar2S/mRrAvG5WDIqOmTFwJuTFesNdNtROeax46gFq+NEyMSgwq3C1/HsI4TmoBSmgKwUICl3ZRcFqoQBBoYXKNIeuFCAodGUXBauFAgSFFirTHLpSgKDQlV0UrBYKEBRaqExz6EoBgkJXdlGwWihAUGihMs2hKwUICl3ZRcFqoYDgzzy0COLfObjVd7W1tWhjl4cqvZnNZmi1yJWxUx5C/mnpx6KEVdcBBcWjGjOmZm0wmUwICwsT0lRyvaW3l4UiQnI/qR2ejHZjenGB8hAQTks/fi3ZkJAg7r8EAgYKDojSh9/R2PQZW7ZmCsjpX3VRfoHjB4H+9RbXiwPi9kQnGlvZPLZRHiuppqUf9Z8+wGg0rhSOqy4gnimcQLx526AaEK6MVdxxAlHX+F41IFQM3zX0/57HqkNBQLjOxYDY+d+B4ExYVSgIiIDgwBUEAbEsxapB0T9sdTxD6P2WaYCZdTxD6P2WifJwfTeIW6N9peAyaqqfIzs99m9PGXvcyrsfQ+w/AR48gqgo5ddi+wqtv6UN44NDyIyM99VEUjm38m5gnv0nwGNsHiqsKfcVDOXBrwznB9YEobLpnaxnuj+CqNQ+ndlvuwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=RGBA size=197x27>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "# This returns a tensor\n",
    "inputs = Input(shape=(4,))\n",
    "\n",
    "# a layer instance is callable on a tensor, and returns a tensor\n",
    "x = Dense(64, activation='relu')(inputs)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# This creates a model that includes\n",
    "# the Input layer and three Dense layers\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(optimizer='Nadam',\n",
    " loss='binary_crossentropy',\n",
    " metrics=['accuracy'])\n",
    "model.fit(x_train, y_train,epochs=100, batch_size=10) # starts training\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import visualkeras\n",
    "plot_model(model, show_shapes=True, show_layer_names=False)\n",
    "\n",
    "# Modify the visualization to show neuron counts\n",
    "for layer in model.layers:\n",
    "    print(layer.name, layer.output_shape)\n",
    "\n",
    "# Visualize the model with neuron counts\n",
    "visualkeras.layered_view(model, to_file='model_with_neurons.png', spacing=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
